{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and model if not continuing from before\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import time\n",
    "from lerobot.common.datasets.utils import hf_transform_to_torch\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "\n",
    "\n",
    "dataset_path = \"../datasets/byol/grasp_100_2024-09-06_17-03-47.hf\"\n",
    "dataset_name = Path(dataset_path).stem\n",
    "dataset = load_from_disk(dataset_path)\n",
    "dataset.set_transform(hf_transform_to_torch)\n",
    "# dataset.set_format(\"torch\")\n",
    "\n",
    "checkpoint = torch.load(\"../VINN/ckpts/resnet_byol_grasp_100_2024-09-06_17-03-47_2024-10-12_21-08/epoch_10.pt\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\")\n",
    "\n",
    "# Remove the fc/classification layer\n",
    "resnet = torchvision.models.resnet18()\n",
    "modules = list(resnet.children())[:-1]\n",
    "backbone = torch.nn.Sequential(*modules)\n",
    "net = backbone\n",
    "net.load_state_dict(checkpoint[\"policy_state_dict\"])\n",
    "net = net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(dataset))\n",
    "print(idx)\n",
    "\n",
    "img = dataset[idx][\"observation.pixels.side\"].unsqueeze(0).to(device)\n",
    "\n",
    "# net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "train_nodes, _ = get_graph_node_names(net)\n",
    "print(train_nodes)\n",
    "return_nodes = [\"4\", '5', '6']\n",
    "model2 = create_feature_extractor(net, return_nodes=return_nodes)\n",
    "intermediate_outputs = model2(img)\n",
    "print(intermediate_outputs)\n",
    "for k in intermediate_outputs:\n",
    "  print(intermediate_outputs[k].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_nodes = [\"4\", '5', '6']\n",
    "model2 = create_feature_extractor(net, return_nodes=return_nodes)\n",
    "intermediate_outputs = model2(img)\n",
    "print(intermediate_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in intermediate_outputs:\n",
    "  print(intermediate_outputs[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_image(img.detach().cpu().squeeze().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key in intermediate_outputs.keys():\n",
    "  print(f\"Plot {key}\")\n",
    "  plt_data = intermediate_outputs[key].detach().cpu().squeeze().numpy()\n",
    "  ncols = min(plt_data.shape[0], 8)\n",
    "  nrows= int(np.ceil(plt_data.shape[0]/ncols))\n",
    "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, sharex=True, sharey=True, figsize=(ncols*1+0.5, nrows*1+0.5), constrained_layout=True)\n",
    "  for i in range(plt_data.shape[0]):\n",
    "      ax = axs.flatten()[i]\n",
    "      ax.imshow(plt_data[i])\n",
    "      ax.set_axis_off()\n",
    "      # ax.set_title(i)\n",
    "  plt.suptitle(f\"{key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_random = torchvision.models.resnet18().to(\"cuda\")\n",
    "return_nodes = ['layer1', 'layer2', 'layer3']\n",
    "resnet_random2 = create_feature_extractor(resnet_random, return_nodes=return_nodes)\n",
    "intermediate_outputs = resnet_random2(img)\n",
    "\n",
    "for k in intermediate_outputs:\n",
    "  print(intermediate_outputs[k].shape)\n",
    "\n",
    "for key in intermediate_outputs.keys():\n",
    "  print(f\"Plot {key}\")\n",
    "  plt_data = intermediate_outputs[key].detach().cpu().squeeze().numpy()\n",
    "  ncols = min(plt_data.shape[0], 8)\n",
    "  nrows= int(np.ceil(plt_data.shape[0]/ncols))\n",
    "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, sharex=True, sharey=True, figsize=(ncols*1+0.5, nrows*1+0.5), constrained_layout=True)\n",
    "  for i in range(plt_data.shape[0]):\n",
    "      ax = axs.flatten()[i]\n",
    "      ax.imshow(plt_data[i])\n",
    "      ax.set_axis_off()\n",
    "      # ax.set_title(i)\n",
    "  plt.suptitle(f\"{key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_default = torchvision.models.resnet18(weights=\"DEFAULT\").to(\"cuda\")\n",
    "return_nodes = ['layer1', 'layer2', 'layer3']\n",
    "resnet_default2 = create_feature_extractor(resnet_default, return_nodes=return_nodes)\n",
    "intermediate_outputs = resnet_default2(img)\n",
    "\n",
    "for k in intermediate_outputs:\n",
    "  print(intermediate_outputs[k].shape)\n",
    "\n",
    "for key in intermediate_outputs.keys():\n",
    "  print(f\"Plot {key}\")\n",
    "  plt_data = intermediate_outputs[key].detach().cpu().squeeze().numpy()\n",
    "  ncols = min(plt_data.shape[0], 8)\n",
    "  nrows= int(np.ceil(plt_data.shape[0]/ncols))\n",
    "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, sharex=True, sharey=True, figsize=(ncols*1+0.5, nrows*1+0.5), constrained_layout=True)\n",
    "  for i in range(plt_data.shape[0]):\n",
    "      ax = axs.flatten()[i]\n",
    "      ax.imshow(plt_data[i])\n",
    "      ax.set_axis_off()\n",
    "      # ax.set_title(i)\n",
    "  plt.suptitle(f\"{key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = torch.load(\"../VINN/ckpts/resnet_byol_grasp_100_2024-09-06_17-03-47_2024-10-15_21-08/epoch_100.pt\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\")\n",
    "\n",
    "# Remove the fc/classification layer\n",
    "resnet = torchvision.models.resnet18()\n",
    "modules = list(resnet.children())[:-1]\n",
    "backbone = torch.nn.Sequential(*modules)\n",
    "net = backbone\n",
    "net.load_state_dict(checkpoint[\"policy_state_dict\"])\n",
    "net = net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_image(img.detach().cpu().squeeze().permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "train_nodes, _ = get_graph_node_names(net)\n",
    "print(train_nodes)\n",
    "return_nodes = [\"4\", '5', '6']\n",
    "model2 = create_feature_extractor(net, return_nodes=return_nodes)\n",
    "intermediate_outputs = model2(img)\n",
    "print(intermediate_outputs)\n",
    "for k in intermediate_outputs:\n",
    "  print(intermediate_outputs[k].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key in intermediate_outputs.keys():\n",
    "  print(f\"Plot {key}\")\n",
    "  plt_data = intermediate_outputs[key].detach().cpu().squeeze().numpy()\n",
    "  ncols = min(plt_data.shape[0], 8)\n",
    "  nrows= int(np.ceil(plt_data.shape[0]/ncols))\n",
    "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, sharex=True, sharey=True, figsize=(ncols*1+0.5, nrows*1+0.5), constrained_layout=True)\n",
    "  for i in range(plt_data.shape[0]):\n",
    "      ax = axs.flatten()[i]\n",
    "      ax.imshow(plt_data[i])\n",
    "      ax.set_axis_off()\n",
    "      # ax.set_title(i)\n",
    "  plt.suptitle(f\"{key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset[idx][\"observation.pixels.gripper\"].unsqueeze(0).to(device)\n",
    "train_nodes, _ = get_graph_node_names(net)\n",
    "print(train_nodes)\n",
    "return_nodes = [\"4\", '5', '6']\n",
    "model2 = create_feature_extractor(net, return_nodes=return_nodes)\n",
    "intermediate_outputs = model2(img)\n",
    "print(intermediate_outputs)\n",
    "for k in intermediate_outputs:\n",
    "  print(intermediate_outputs[k].shape)\n",
    "\n",
    "for key in intermediate_outputs.keys():\n",
    "  print(f\"Plot {key}\")\n",
    "  plt_data = intermediate_outputs[key].detach().cpu().squeeze().numpy()\n",
    "  ncols = min(plt_data.shape[0], 8)\n",
    "  nrows= int(np.ceil(plt_data.shape[0]/ncols))\n",
    "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, sharex=True, sharey=True, figsize=(ncols*1+0.5, nrows*1+0.5), constrained_layout=True)\n",
    "  for i in range(plt_data.shape[0]):\n",
    "      ax = axs.flatten()[i]\n",
    "      ax.imshow(plt_data[i])\n",
    "      ax.set_axis_off()\n",
    "      # ax.set_title(i)\n",
    "  plt.suptitle(f\"{key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
