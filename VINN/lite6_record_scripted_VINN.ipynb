{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "import gym_lite6.env, gym_lite6.scripted_policy, gym_lite6.pickup_task\n",
    "# Had to export this before starting jupyter server\n",
    "%env MUJOCO_GL=egl \n",
    "import mujoco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "reload(gym_lite6.env)\n",
    "reload(gym_lite6.utils)\n",
    "reload(gym_lite6.scripted_policy)\n",
    "reload(gym_lite6.pickup_task)\n",
    "\n",
    "task = gym_lite6.pickup_task.GraspTask('gripper_left_finger', 'gripper_right_finger', 'box', 'floor')\n",
    "# task = gym_lite6.pickup_task.GraspAndLiftTask('gripper_left_finger', 'gripper_right_finger', 'box', 'floor')\n",
    "\n",
    "env = gym.make(\n",
    "    \"UfactoryCubePickup-v0\",\n",
    "    task=task,\n",
    "    obs_type=\"pixels_state\",\n",
    "    action_type=\"qvel\",\n",
    "    max_episode_steps=100,\n",
    "    visualization_width=320,\n",
    "    visualization_height=240,\n",
    "    render_fps=10\n",
    ")\n",
    "\n",
    "observation, info = env.reset()\n",
    "media.show_image(env.unwrapped.render(camera=\"side_cam\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qpos0 = None\n",
    "# box_pos0 = None\n",
    "# box_quat0 = None\n",
    "\n",
    "qpos0 = np.array([0, 0.541, 1.49 , 2.961, 0.596, 0.203])\n",
    "box_pos0 = np.array([0.2, 0, 0.0])\n",
    "box_quat0 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a scripted rollout\n",
    "Important hyperparams:\n",
    "- kv in the actuator gains in the model XML - higher makes it reach setpoint with greater precision\n",
    "- Kp, Kp_ang\n",
    "- damping - higher gives smoother motions/less craziness around singularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a scripted rollout\n",
    "\n",
    "policy = gym_lite6.scripted_policy.GraspPolicy(env, 'end_effector', 'box', 'gripper_left_finger', 'gripper_right_finger', max_vel=0.3)\n",
    "# policy = gym_lite6.scripted_policy.GraspAndLiftPolicy(env, 'end_effector', 'box', 'gripper_left_finger', 'gripper_right_finger', max_vel=0.2)\n",
    "\n",
    "# Reset the policy and environmens to prepare for rollout\n",
    "policy.reset()\n",
    "observation, info = env.reset(seed=69, qpos=qpos0, box_pos=box_pos0, box_quat=box_quat0)\n",
    "\n",
    "action = {}\n",
    "Kp = 0.4\n",
    "Kp_ang = 0.4\n",
    "# Ki = 0\n",
    "# i_bounds = [-1,1]\n",
    "# i_error = np.zeros(env.unwrapped.dof)\n",
    "\n",
    "\n",
    "frames = []\n",
    "# Render frame of the initial state\n",
    "frames.append(env.render())\n",
    "\n",
    "step = 0\n",
    "done = False\n",
    "\n",
    "ep_dict = {\"action.qpos\": [], \"action.qvel\": [], \"action.gripper\": [],\"action.ee_vel\": [], \"action.ee_ang_vel\": [],\n",
    "           \"observation.state.qpos\": [], \"observation.state.qvel\": [], \"observation.state.gripper\": [], \"observation.pixels.side\": [], \"observation.pixels.gripper\": [],\n",
    "           \"observation.ee_pose.pos\": [], \"observation.ee_pose.quat\": [], \"observation.ee_pose.vel\": [], \"observation.ee_pose.ang_vel\": [],\n",
    "           \"reward\": [], \"timestamp\": [], \"frame_index\": [],\n",
    "           }\n",
    "\n",
    "while not done:\n",
    "  action = policy(env.unwrapped.model, env.unwrapped.data, observation, info)\n",
    "  delta = action[\"pos\"] - observation[\"ee_pose\"][\"pos\"]\n",
    "\n",
    "  # Quaternion error\n",
    "  quat_err = np.empty(4)\n",
    "  curr_quat = observation[\"ee_pose\"][\"quat\"]\n",
    "  curr_quat_conj = np.empty(4)\n",
    "  ang_delta = np.empty(3)\n",
    "  mujoco.mju_negQuat(curr_quat_conj, curr_quat)\n",
    "  mujoco.mju_mulQuat(quat_err, action[\"quat\"], curr_quat_conj)\n",
    "  mujoco.mju_quat2Vel(ang_delta, quat_err, 1.0)\n",
    "  \n",
    "  # Convert to velocity (in world frame)\n",
    "  vel = Kp * delta * env.metadata[\"render_fps\"]\n",
    "  ang_vel = Kp_ang * ang_delta * env.metadata[\"render_fps\"]\n",
    "  # Transform to end effector frame\n",
    "  action[\"qvel\"] = env.unwrapped.solve_ik_vel(vel, ang_vel, ref_frame='end_effector', local=False, damping=4e-4)\n",
    "\n",
    "  # for i in range(3):\n",
    "  observation, reward, terminated, truncated, info = env.step(action)\n",
    "    # The rollout is considered done when the success state is reach (i.e. terminated is True),\n",
    "    # or the maximum number of iterations is reached (i.e. truncated is True)\n",
    "  done = terminated | truncated | done\n",
    "    # if done:\n",
    "    #   break\n",
    "\n",
    "  ep_dict[\"action.qpos\"].append(action[\"qpos\"])\n",
    "  ep_dict[\"action.qvel\"].append(action[\"qvel\"])\n",
    "  ep_dict[\"action.ee_vel\"].append(vel)\n",
    "  ep_dict[\"action.ee_ang_vel\"].append(ang_vel)\n",
    "  ep_dict[\"action.gripper\"].append(action[\"gripper\"])\n",
    "  ep_dict[\"observation.state.qpos\"].append(observation[\"state\"][\"qpos\"])\n",
    "  ep_dict[\"observation.state.qvel\"].append(observation[\"state\"][\"qvel\"])\n",
    "  ep_dict[\"observation.state.gripper\"].append(observation[\"state\"][\"gripper\"])\n",
    "  ep_dict[\"observation.pixels.side\"].append(observation[\"pixels\"][\"side\"])\n",
    "  ep_dict[\"observation.pixels.gripper\"].append(observation[\"pixels\"][\"gripper\"])\n",
    "  ep_dict[\"observation.ee_pose.pos\"].append(observation[\"ee_pose\"][\"pos\"])\n",
    "  ep_dict[\"observation.ee_pose.quat\"].append(observation[\"ee_pose\"][\"quat\"])\n",
    "  ep_dict[\"observation.ee_pose.vel\"].append(observation[\"ee_pose\"][\"vel\"])\n",
    "  ep_dict[\"observation.ee_pose.ang_vel\"].append(observation[\"ee_pose\"][\"ang_vel\"])\n",
    "  ep_dict[\"reward\"].append(reward)\n",
    "  ep_dict[\"timestamp\"].append(env.unwrapped.data.time)\n",
    "  ep_dict[\"frame_index\"].append(step)\n",
    "\n",
    "  print(f\"{step=} {reward=} {terminated=}\")\n",
    "\n",
    "  step += 1\n",
    "\n",
    "if terminated:\n",
    "  print(\"Success!\")\n",
    "else:\n",
    "  print(f\"Failure! Reached {policy.stage}\")\n",
    "\n",
    "media.show_video(ep_dict[\"observation.pixels.side\"], fps=env.metadata[\"render_fps\"])\n",
    "media.show_video(ep_dict[\"observation.pixels.gripper\"], fps=env.metadata[\"render_fps\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ep_dict.keys())\n",
    "\n",
    "gym_lite6.utils.plot_dict_of_arrays(ep_dict, \"timestamp\", keys=[\"action.ee_vel\", \"action.ee_ang_vel\", \"action.qvel\", \"observation.state.qpos\", \"observation.state.qvel\", \"observation.state.gripper\", \"reward\"], sharey=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record to HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lerobot.common.datasets.push_dataset_to_hub.utils\n",
    "from datasets import Dataset, Features, Image, Sequence, Value\n",
    "from lerobot.common.datasets.utils import (\n",
    "    hf_transform_to_torch,\n",
    ")\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def record_episodes_to_hf(env, policy, dataset_dir, num_ep=1, num_frames=300):\n",
    "  features = {}\n",
    "  num_readings = num_ep*num_frames\n",
    "  features[\"observation.pixels.side\"] = Image()\n",
    "  features[\"observation.pixels.gripper\"] = Image()\n",
    "  features[\"observation.state.qpos\"] = Sequence(length=6, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"observation.state.qvel\"] = Sequence(length=6, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"observation.state.gripper\"] = Value(dtype=\"int8\", id=None)\n",
    "  features[\"observation.ee_pose.pos\"] = Sequence(length=3, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"observation.ee_pose.quat\"] = Sequence(length=4, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"observation.ee_pose.vel\"] = Sequence(length=3, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"observation.ee_pose.ang_vel\"] = Sequence(length=3, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"reward\"] = Value(dtype=\"int8\", id=None)\n",
    "  features[\"action.qpos\"] = Sequence(length=6, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"action.qvel\"] = Sequence(length=6, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"action.ee_vel\"] = Sequence(length=3, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"action.ee_ang_vel\"] = Sequence(length=3, feature=Value(dtype=\"float32\", id=None))\n",
    "  features[\"action.gripper\"] = Value(dtype=\"int8\", id=None)\n",
    "  features[\"episode_index\"] = Value(dtype=\"int64\", id=None) # Which episode\n",
    "  features[\"frame_index\"] = Value(dtype=\"int64\", id=None) # Which frame within episode\n",
    "  features[\"timestamp\"] = Value(dtype=\"float32\", id=None)\n",
    "  features[\"index\"] = Value(dtype=\"int64\", id=None) # Which frame in the whole datasets\n",
    "\n",
    "  if not os.path.isdir(dataset_dir):\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "  successful_trajectories = 0\n",
    "  data_dict = {\n",
    "      \"action.qpos\": [], \"action.qvel\": [], \"action.gripper\": [],\"action.ee_vel\": [], \"action.ee_ang_vel\": [],\n",
    "      \"observation.state.qpos\": [], \"observation.state.qvel\": [], \"observation.state.gripper\": [], \"observation.pixels.side\": [], \"observation.pixels.gripper\": [],\n",
    "      \"observation.ee_pose.pos\": [], \"observation.ee_pose.quat\": [], \"observation.ee_pose.vel\": [], \"observation.ee_pose.ang_vel\": [],\n",
    "      \"reward\": [], \"timestamp\": [], \"frame_index\": [],\n",
    "      \"episode_index\": [], \"index\": []\n",
    "      }\n",
    "  while successful_trajectories < num_ep:\n",
    "    ep_idx = successful_trajectories\n",
    "    print(f\"Episode {ep_idx}\")\n",
    "    observation, info = env.reset(qpos=None, box_pos=None, box_quat=None)\n",
    "    policy.reset()\n",
    "\n",
    "    ep_dict = {\n",
    "      \"action.qpos\": [], \"action.qvel\": [], \"action.gripper\": [],\"action.ee_vel\": [], \"action.ee_ang_vel\": [],\n",
    "      \"observation.state.qpos\": [], \"observation.state.qvel\": [], \"observation.state.gripper\": [], \"observation.pixels.side\": [], \"observation.pixels.gripper\": [],\n",
    "      \"observation.ee_pose.pos\": [], \"observation.ee_pose.quat\": [], \"observation.ee_pose.vel\": [], \"observation.ee_pose.ang_vel\": [],\n",
    "      \"reward\": [], \"timestamp\": [], \"frame_index\": [],\n",
    "      }\n",
    "    ep_dict[\"episode_index\"] = [ep_idx] * num_frames\n",
    "\n",
    "    for step in range(num_frames):\n",
    "      action = policy(env.unwrapped.model, env.unwrapped.data, observation, info)\n",
    "      delta = action[\"pos\"] - observation[\"ee_pose\"][\"pos\"]\n",
    "\n",
    "      # Quaternion error\n",
    "      quat_err = np.empty(4)\n",
    "      curr_quat = observation[\"ee_pose\"][\"quat\"]\n",
    "      curr_quat_conj = np.empty(4)\n",
    "      ang_delta = np.empty(3)\n",
    "      mujoco.mju_negQuat(curr_quat_conj, curr_quat)\n",
    "      mujoco.mju_mulQuat(quat_err, action[\"quat\"], curr_quat_conj)\n",
    "      mujoco.mju_quat2Vel(ang_delta, quat_err, 1.0)\n",
    "      \n",
    "      # Convert to velocity (in world frame)\n",
    "      vel = Kp * delta * env.metadata[\"render_fps\"]\n",
    "      ang_vel = Kp_ang * ang_delta * env.metadata[\"render_fps\"]\n",
    "      # Transform to end effector frame\n",
    "      action[\"qvel\"] = env.unwrapped.solve_ik_vel(vel, ang_vel, ref_frame='end_effector', local=False)\n",
    "\n",
    "      observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "      ep_dict[\"action.qpos\"].append(action[\"qpos\"])\n",
    "      ep_dict[\"action.qvel\"].append(action[\"qvel\"])\n",
    "      ep_dict[\"action.ee_vel\"].append(vel)\n",
    "      ep_dict[\"action.ee_ang_vel\"].append(ang_vel)\n",
    "      ep_dict[\"action.gripper\"].append(action[\"gripper\"])\n",
    "      ep_dict[\"observation.state.qpos\"].append(observation[\"state\"][\"qpos\"])\n",
    "      ep_dict[\"observation.state.qvel\"].append(observation[\"state\"][\"qvel\"])\n",
    "      ep_dict[\"observation.state.gripper\"].append(observation[\"state\"][\"gripper\"])\n",
    "      ep_dict[\"observation.pixels.side\"].append(observation[\"pixels\"][\"side\"])\n",
    "      ep_dict[\"observation.pixels.gripper\"].append(observation[\"pixels\"][\"gripper\"])\n",
    "      ep_dict[\"observation.ee_pose.pos\"].append(observation[\"ee_pose\"][\"pos\"])\n",
    "      ep_dict[\"observation.ee_pose.quat\"].append(observation[\"ee_pose\"][\"quat\"])\n",
    "      ep_dict[\"observation.ee_pose.vel\"].append(observation[\"ee_pose\"][\"vel\"])\n",
    "      ep_dict[\"observation.ee_pose.ang_vel\"].append(observation[\"ee_pose\"][\"ang_vel\"])\n",
    "      ep_dict[\"reward\"].append(reward)\n",
    "      ep_dict[\"timestamp\"].append(env.unwrapped.data.time)\n",
    "      ep_dict[\"frame_index\"].append(step)\n",
    "    \n",
    "    if policy.done and terminated:\n",
    "      \n",
    "      # for key in ep_dict:\n",
    "      #   # Setting the dtype/transforming to a tensor makes no difference as HF Datasets stores everything in Arrow format anyway\n",
    "      #   dtype = getattr(torch, features[key].feature.dtype) if 'feature' in features[key].__dict__ and features[key].feature.dtype in torch.__dict__ else None\n",
    "      #   ep_dict[key] = torch.tensor(ep_dict[key], dtype=dtype)\n",
    "            \n",
    "      media.show_video(ep_dict[\"observation.pixels.side\"], fps=env.metadata[\"render_fps\"])\n",
    "      for key in ep_dict:\n",
    "        data_dict[key].extend(ep_dict[key])\n",
    "\n",
    "      base_idx = successful_trajectories*num_frames\n",
    "      data_dict[\"index\"].extend(range(base_idx, base_idx + num_frames))\n",
    "\n",
    "      successful_trajectories += 1\n",
    "    else:\n",
    "      print(\"Failed, retrying\", policy.done, terminated)\n",
    "\n",
    "  print(\"Creating dataset\")\n",
    "  # data_dict = concatenate_episodes(ep_dicts)\n",
    "  # print(data_dict, features)\n",
    "  hf_dataset = Dataset.from_dict(data_dict, features=Features(features))\n",
    "  \n",
    "  hf_dataset.save_to_disk(dataset_dir + f\"/grasp_ee_vel_fixed_{num_ep}_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.hf\")\n",
    "\n",
    "  return hf_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = gym_lite6.scripted_policy.GraspPolicy(env, 'end_effector', 'box', 'gripper_left_finger', 'gripper_right_finger', max_vel=0.2)\n",
    "# policy = gym_lite6.scripted_policy.GraspAndLiftPolicy(env, 'end_effector', 'box', 'gripper_left_finger', 'gripper_right_finger', max_vel=0.2)\n",
    "# record_episodes(env, policy, \"dataset/pickup_side_cam\", n=50)\n",
    "hf_dataset = record_episodes_to_hf(env, policy, \"../datasets/grasp\", num_ep=2, num_frames=100)\n",
    "hf_dataset.set_transform(hf_transform_to_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
