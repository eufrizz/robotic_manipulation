{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "import torch\n",
    "# torch.multiprocessing.set_start_method('spawn')\n",
    "import gym_lite6.env, gym_lite6.pickup_task, gym_lite6.utils\n",
    "%env MUJOCO_GL=egl # Had to export this before starting jupyter server\n",
    "# import mujoco\n",
    "from importlib import reload\n",
    "# reload(gym_lite6.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = \"../datasets/grasp/grasp_qvel_random_1_2024-10-14_20-00-45.hf\"\n",
    "dataset = load_from_disk(str(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_idx = 0\n",
    "episode_data = dataset.filter(lambda example: example['episode_index'] == episode_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qpos control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(gym_lite6.env)\n",
    "\n",
    "task = gym_lite6.pickup_task.GraspAndLiftTask('gripper_left_finger', 'gripper_right_finger', 'box', 'floor')\n",
    "env = gym.make(\n",
    "    \"UfactoryCubePickup-v0\",\n",
    "    task=task,\n",
    "    obs_type=\"pixels_state\",\n",
    "    max_episode_steps=300,\n",
    ")\n",
    "observation, info = env.reset()\n",
    "media.show_image(env.render(), width=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset(qpos=np.array([0, 0, 0, 0, 0, 0]), box_pos=np.array([0.1, 0, 0.0]))\n",
    "media.show_image(env.render(), width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replay_frames = []\n",
    "orig_frames = []\n",
    "gripper_frames = []\n",
    "observation, info = env.reset(qpos=episode_data[\"action.qpos\"][0])\n",
    "for data in episode_data:\n",
    "    action = {\"gripper\": data[\"action.gripper\"], \"qpos\": data[\"action.qpos\"]}\n",
    "    # print(action)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    # print(observation)\n",
    "    replay_frames.append(observation[\"pixels\"][\"side\"])\n",
    "    orig_frames.append(np.array(data[\"observation.pixels.side\"]))\n",
    "    gripper_frames.append(np.array(data[\"observation.pixels.gripper\"]))\n",
    "    # orig_frames.append(data[\"observation.pixels.side\"])\n",
    "\n",
    "media.show_videos([replay_frames, orig_frames, gripper_frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(observation[\"pixels\"][\"side\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_lite6.utils.plot_dict_of_arrays(episode_data, \"timestamp\", keys=[\"action.qpos\", \"observation.state.qpos\", \"observation.state.qvel\", \"observation.state.gripper\", \"reward\"], sharey=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data[\"timestam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vars = ['action.qpos', 'observation.state.qpos', 'action.gripper', 'observation.state.gripper', 'reward']\n",
    "xax = 'timestamp'\n",
    "for var in vars:\n",
    "  if hasattr(episode_data[0][var], '__iter__'):\n",
    "    len_state = len(episode_data[0][var])\n",
    "  else:\n",
    "    len_state = 1\n",
    "  ncols = len_state; nrows= int(np.ceil(len_state/ncols))\n",
    "  plt_data = torch.tensor(episode_data[var])\n",
    "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, sharex=True, sharey=True, figsize=(ncols*2+0.5, nrows*2+1), constrained_layout=True)\n",
    "\n",
    "  for i in range(len_state):\n",
    "    # ax = plt.subplot(int(np.ceil(len_qpos/3)), 3, i+1)\n",
    "    if len_state > 1:\n",
    "      ax = axs.flatten()[i]\n",
    "      ax.plot(episode_data[xax], plt_data[:, i])\n",
    "      ax.set_title(i)\n",
    "    else:\n",
    "      ax = axs\n",
    "      ax.plot(episode_data[xax], plt_data)\n",
    "\n",
    "  # fig.add_subplot(111, frameon=False)\n",
    "  plt.suptitle(f\"ep{episode_idx}: {var}\")\n",
    "  # fig.supylabel(\"Joint angle\")\n",
    "  fig.supxlabel(xax)\n",
    "  # plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "  # fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qvel control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(gym_lite6.env)\n",
    "\n",
    "task = gym_lite6.pickup_task.GraspAndLiftTask('gripper_left_finger', 'gripper_right_finger', 'box', 'floor')\n",
    "env = gym.make(\n",
    "    \"UfactoryCubePickup-v0\",\n",
    "    task=task,\n",
    "    obs_type=\"pixels_state\",\n",
    "    action_type=\"qvel\",\n",
    "    max_episode_steps=300,\n",
    ")\n",
    "observation, info = env.reset()\n",
    "media.show_image(env.render(), width=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_frames = []\n",
    "orig_frames = []\n",
    "gripper_frames = []\n",
    "observation, info = env.reset(qpos=episode_data[\"action.qpos\"][0])\n",
    "for data in episode_data:\n",
    "    action = {\"gripper\": data[\"action.gripper\"], \"qvel\": data[\"action.qvel\"]}\n",
    "    # print(action)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    # print(observation)\n",
    "    replay_frames.append(observation[\"pixels\"][\"side\"])\n",
    "    orig_frames.append(np.array(data[\"observation.pixels.side\"]))\n",
    "    gripper_frames.append(np.array(data[\"observation.pixels.gripper\"]))\n",
    "    # orig_frames.append(data[\"observation.pixels.side\"])\n",
    "\n",
    "media.show_videos([replay_frames, orig_frames, gripper_frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
