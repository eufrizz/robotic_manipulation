{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import gym_aloha\n",
    "import mediapy as media\n",
    "import torch\n",
    "from act.policy import ACTPolicy\n",
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This scripts demonstrates how to evaluate a pretrained policy from the HuggingFace Hub or from your local\n",
    "training outputs directory. In the latter case, you might want to run examples/3_train_policy.py first.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import gym_aloha  # noqa: F401\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import numpy\n",
    "import torch\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from lerobot.common.policies.act.modeling_act import ACTPolicy\n",
    "\n",
    "# Create a directory to store the video of the evaluation\n",
    "output_directory = Path(\"lerobot/outputs/eval/act_aloha_sim_transfer_cube_human\")\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Download the diffusion policy for pusht environment\n",
    "pretrained_policy_path = Path(snapshot_download(\"lerobot/act_aloha_sim_transfer_cube_human\"))\n",
    "# OR uncomment the following to evaluate a policy from the local outputs/train folder.\n",
    "# pretrained_policy_path = Path(\"outputs/train/example_pusht_diffusion\")\n",
    "\n",
    "policy = ACTPolicy.from_pretrained(pretrained_policy_path)\n",
    "policy.eval()\n",
    "policy.to(device)\n",
    "\n",
    "# Initialize evaluation environment to render two observation types:\n",
    "# an image of the scene and state/position of the agent. The environment\n",
    "# also automatically stops running after 300 interactions/steps.\n",
    "# gym.envs.pprint_registry() to find out what's available\n",
    "# (\"AlohaInsertion-v0\", \"pixels\"),\n",
    "# (\"AlohaInsertion-v0\", \"pixels_agent_pos\"),\n",
    "# (\"AlohaTransferCube-v0\", \"pixels\"),\n",
    "# (\"AlohaTransferCube-v0\", \"pixels_agent_pos\"),\n",
    "env = gym.make(\n",
    "    \"gym_aloha/AlohaTransferCube-v0\",\n",
    "    obs_type=\"pixels_agent_pos\",\n",
    "    max_episode_steps=300,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset the policy and environmens to prepare for rollout\n",
    "policy.reset()\n",
    "numpy_observation, info = env.reset(seed=69)\n",
    "\n",
    "# Prepare to collect every rewards and all the frames of the episode,\n",
    "# from initial state to final state.\n",
    "rewards = []\n",
    "frames = []\n",
    "\n",
    "# Render frame of the initial state\n",
    "frames.append(env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "done = False\n",
    "# while len(frames) < 300:\n",
    "while not done:\n",
    "    # Prepare observation for the policy running in Pytorch\n",
    "    state = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    image = torch.from_numpy(numpy_observation[\"pixels\"][\"top\"])\n",
    "\n",
    "    # Convert to float32 with image from channel first in [0,255]\n",
    "    # to channel last in [0,1]\n",
    "    state = state.to(torch.float32)\n",
    "    image = image.to(torch.float32) / 255\n",
    "    image = image.permute(2, 0, 1)\n",
    "\n",
    "    # Send data tensors from CPU to GPU\n",
    "    state = state.to(device, non_blocking=True)\n",
    "    image = image.to(device, non_blocking=True)\n",
    "\n",
    "    # Add extra (empty) batch dimension, required to forward the policy\n",
    "    state = state.unsqueeze(0)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Create the policy input dictionary\n",
    "    observation = {\n",
    "        \"observation.state\": state,\n",
    "        \"observation.images.top\": image,\n",
    "    }\n",
    "\n",
    "    # Predict the next action with respect to the current observation\n",
    "    with torch.inference_mode():\n",
    "        action = policy.select_action(observation)\n",
    "\n",
    "    # Prepare the action for the environment\n",
    "    numpy_action = action.squeeze(0).to(\"cpu\").numpy()\n",
    "\n",
    "    # Step through the environment and receive a new observation\n",
    "    numpy_observation, reward, terminated, truncated, info = env.step(numpy_action)\n",
    "    print(f\"{step=} {reward=} {terminated=}\")\n",
    "\n",
    "    # Keep track of all the rewards and frames\n",
    "    rewards.append(reward)\n",
    "    frames.append(env.render())\n",
    "\n",
    "    # The rollout is considered done when the success state is reach (i.e. terminated is True),\n",
    "    # or the maximum number of iterations is reached (i.e. truncated is True)\n",
    "    done = terminated | truncated | done\n",
    "    step += 1\n",
    "\n",
    "if terminated:\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"Failure!\")\n",
    "\n",
    "# Get the speed of environment (i.e. its number of frames per second).\n",
    "fps = env.metadata[\"render_fps\"]\n",
    "\n",
    "media.show_video(frames, fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = gym.make(\"gym_aloha/AlohaInsertion-v0\")\n",
    "observation, info = env.reset()\n",
    "frames = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = policy.predict(observation)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    image = env.render()\n",
    "    frames.append(image)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()\n",
    "\n",
    "media.show_video(frames, fps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "from pathlib import Path\n",
    "# np.set_printoptions(precision=10, suppress=True, linewidth=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetDataKeyframe(model, data, 0)\n",
    "mujoco.mj_forward(model, data)\n",
    "\n",
    "# Make a Renderer and a camera.\n",
    "renderer = mujoco.Renderer(model, height=360, width=480)\n",
    "camera = mujoco.MjvCamera()\n",
    "mujoco.mjv_defaultFreeCamera(model, camera)\n",
    "camera.distance = 1.2\n",
    "camera.elevation = -15\n",
    "camera.azimuth = -130\n",
    "camera.lookat = (0, 0, 0.3)\n",
    "\n",
    "# Visualize site frames and labels\n",
    "voption = mujoco.MjvOption()\n",
    "voption.frame = mujoco.mjtFrame.mjFRAME_SITE\n",
    "renderer.update_scene(data, camera, scene_option=voption)\n",
    "\n",
    "media.show_image(renderer.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Pick up, put down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_lite6.env\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera2 = mujoco.MjvCamera()\n",
    "camera2.distance = 1.2\n",
    "camera2.elevation = -15\n",
    "camera2.azimuth = -60\n",
    "camera2.lookat = (0, 0, 0.3)\n",
    "\n",
    "voption = mujoco.MjvOption()\n",
    "voption.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
    "voption.flags[mujoco.mjtVisFlag.mjVIS_CONTACTFORCE] = True\n",
    "voption.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = True\n",
    "renderer.update_scene(data, camera, scene_option=voption)\n",
    "f1 = renderer.render()\n",
    "renderer.update_scene(data, camera2, scene_option=voption)\n",
    "f2 = renderer.render()\n",
    "media.show_images([f1, f2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test IK from env\n",
    "\n",
    "pos = np.array([0.2, 0.2, 0.2])\n",
    "quat = np.array([0, 1, 0, 0])\n",
    "qpos = env.unwrapped.solve_ik(pos, quat)\n",
    "print(qpos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_quat = np.array([0., 1., 0., 0.])\n",
    "ref_quat = np.array([0., 1., 0., 0.])\n",
    "Deffector = np.empty((3, 3))\n",
    "mujoco.mjd_subQuat(target_quat, ref_quat, None, Deffector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.allclose(env.unwrapped.map_bounds(vals=np.array([0, 0.5, 1]), in_range=np.array([[0, 1], [0, 1], [0, 1]]), out_range=np.array([[-1, 1], [-1, 1], [-1, 1]])), np.array([-1, 0, 1])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_image(observation['pixels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_episodes(env, None, \"dataset/test/\", len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"dataset/test/ep_0.hdf5\", \"r\") as f:\n",
    "    for name in f:\n",
    "        print(f[name])\n",
    "    print(f[\"reward\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.contact[0].efc_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.efc_force[data.contact[0].efc_address]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(gym_lite6.env)\n",
    "env = gym.make(\n",
    "    \"UfactoryCubePickup-v0\",\n",
    "    task=task,\n",
    "    obs_type=\"pixels_state\",\n",
    "    max_episode_steps=300,\n",
    ")\n",
    "observation, info = env.reset()\n",
    "media.show_image(env.render())\n",
    "env.data.contact.geom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.data.geom(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path = \"models/cube_pickup.xml\"\n",
    "model = mujoco.MjModel.from_xml_path(scene_path)\n",
    "data = mujoco.MjData(model)\n",
    "renderer = mujoco.Renderer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "data.ctrl[:6] = np.array([0.785399277 , 0.5525638469, 1.0265586618, 0.0000054301, 0.4739905706, 0.7854002379])\n",
    "for i in range(500):\n",
    "  mujoco.mj_step(model, data)\n",
    "print(data.site('end_effector').xpos)\n",
    "renderer.update_scene(data, camera, voption); media.show_image(renderer.render())\n",
    "data.qpos[:6] = np.array([0.785399277 , 0.5525638469, 1.0265586618, 0.0000054301, 0.4739905706, 0.7854002379])\n",
    "mujoco.mj_step(model, data)\n",
    "print(data.site('end_effector').xpos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
